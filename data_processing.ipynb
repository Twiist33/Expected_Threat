{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e9da67-ea57-4b93-b4d3-bd199b3e1184",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Data collection, pre-processing and aggregation / Collecte,pré-traitement et aggrégation des données</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c53a7b-74b0-490d-8413-ad09f4001b2f",
   "metadata": {},
   "source": [
    "### Importing librairies / Importer les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af80d196-5055-4c62-9d11-ccc3349bdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing librairies / Importer les librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "import json\n",
    "import math\n",
    "from typing import Optional, List, Dict\n",
    "from urllib.request import urlopen\n",
    "from hashlib import sha1\n",
    "import os, re, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8564051-6737-4cd0-825d-b10ae020a3cb",
   "metadata": {},
   "source": [
    "### Data recovery and pre-processing / Récupération et pré-traitement des données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6f9de-7b86-4824-b8e7-a7051c7750d2",
   "metadata": {},
   "source": [
    "#### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f890d807-0f0a-441e-bd78-c49e8c5dc873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_events_all() -> pd.DataFrame:\n",
    "    # Match IDs to fetch / Liste des match_id à récupérer\n",
    "    match_ids = [1886347, 1899585, 1925299, 1953632, 1996435,2006229, 2011166, 2013725, 2015213, 2017461]\n",
    "\n",
    "    # Columns to keep / Colonnes à conserver\n",
    "    columns_to_keep_events = [\n",
    "        \"index\", \"match_id\", \"time_start\", \"time_end\", \"period\", \"event_type\",\"event_subtype\", \"player_id\", \"player_name\",\n",
    "        \"player_position\",\"player_in_possession_id\", \"player_in_possession_name\", \"team_id\", \"team_shortname\",\"channel_start\",\n",
    "        \"third_start\", \"penalty_area_start\", \"channel_end\", \"third_end\", \"penalty_area_end\",\"associated_player_possession_end_type\",\n",
    "        \"associated_off_ball_run_subtype\",\"game_state\", \"team_score\", \"opponent_team_score\",\"team_in_possession_phase_type\",\n",
    "        \"team_out_of_possession_phase_type\",\"lead_to_shot\", \"lead_to_goal\", \"speed_avg\", \"speed_avg_band\", \"start_type\", \"end_type\",\n",
    "        \"pass_outcome\", \"player_targeted_id\",\"player_targeted_name\", \"player_targeted_channel_pass\", \"player_targeted_third_pass\",\n",
    "        \"player_targeted_average_speed\", \"player_targeted_speed_avg_band\",\"player_targeted_xthreat\", \"player_targeted_dangerous\",\n",
    "        \"xthreat\", \"dangerous\",\"affected_line_breaking_passing_option_xthreat\",\"affected_line_breaking_passing_option_dangerous\",\n",
    "        \"pressing_chain\", \"possession_danger\", \"beaten_by_possession\",\"beaten_by_movement\", \"stop_possession_danger\",\n",
    "        \"reduce_possession_danger\"\n",
    "    ]\n",
    "\n",
    "    def fetch_and_filter_match(match_id: int) -> Optional[pd.DataFrame]:\n",
    "        # Read the CSV / Lire le CSV\n",
    "        url = f\"https://raw.githubusercontent.com/SkillCorner/opendata/master/data/matches/{match_id}/{match_id}_dynamic_events.csv\"\n",
    "        try:\n",
    "            df = pd.read_csv(url, low_memory=False)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Could not read match_id={match_id} ({e}). / Lecture impossible pour match_id={match_id} ({e}).\")\n",
    "            return None\n",
    "\n",
    "        # Keep only the desired columns / Ne garder que les colonnes souhaitées\n",
    "        keep = [c for c in columns_to_keep_events if c in df.columns]\n",
    "        df = df[keep]\n",
    "        return df\n",
    "\n",
    "    parts = []\n",
    "    for mid in match_ids:\n",
    "        part = fetch_and_filter_match(mid)\n",
    "        if part is not None:\n",
    "            parts.append(part)\n",
    "\n",
    "    if not parts:\n",
    "        raise RuntimeError(\"No file could be retrieved. / Aucun fichier n'a pu être récupéré.\")\n",
    "\n",
    "    events_all = pd.concat(parts, ignore_index=True)\n",
    "    \n",
    "    return events_all\n",
    "\n",
    "# Data recovery and pre-processing / Récupération et pré-traitement des données\n",
    "events_all = build_events_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e73f5da-95ff-46af-888d-547847fa6711",
   "metadata": {},
   "source": [
    "#### Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20212a9b-e6c8-40f2-aabf-74f73387ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Match IDs to fetch / Liste des match_id à récupérer\n",
    "match_ids = [1886347, 1899585, 1925299, 1953632, 1996435, 2006229, 2011166, 2013725, 2015213, 2017461]\n",
    "\n",
    "# Read json url / Lecture du fichier json\n",
    "def _read_json_url(url: str) -> Optional[dict]:\n",
    "    try:\n",
    "        with urlopen(url) as resp:\n",
    "            return json.loads(resp.read().decode(\"utf-8\"))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Impossible de lire {url} ({e})\")\n",
    "        return None\n",
    "\n",
    "# Function to retrieve player information for each match / Fonction pour récupérer les informations des joueurs sur chaque match\n",
    "def _normalize_player_record(p: dict, match_id: int, team_short_map: Dict[int, str]) -> Optional[dict]:\n",
    "    try:\n",
    "        player_id = int(p.get(\"id\"))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # Retrieve of the number of minutes played / Récupération du nombre de minutes jouées\n",
    "    total = (p.get(\"playing_time\") or {}).get(\"total\") or {}\n",
    "    minutes_played = total.get(\"minutes_played\")\n",
    "    try:\n",
    "        minutes_played = float(minutes_played) if minutes_played is not None else 0.0\n",
    "    except:\n",
    "        minutes_played = 0.0\n",
    "\n",
    "    # Retrieve of the player position / Récupération de la position du joueur\n",
    "    role = p.get(\"player_role\") or {}\n",
    "    position_group = role.get(\"position_group\")\n",
    "\n",
    "    # Retrieve of the team id / Récupération de l'identifiant de son équipe\n",
    "    team_id = p.get(\"team_id\")\n",
    "    team_shortname = team_short_map.get(team_id)\n",
    "\n",
    "    # Retrieve of the player name / Récupération du nom du joueurs\n",
    "    player_name = p.get(\"short_name\")\n",
    "\n",
    "    return {\n",
    "        \"match_id\": match_id,\"player_id\": player_id,\"player_name_json\": player_name,\"player_position_json\": position_group,\n",
    "        \"number\": p.get(\"number\"),\"birthday\": p.get(\"birthday\"),\"minutes_played\": minutes_played,\"team_id\": team_id,\n",
    "        \"team_shortname_json\": team_shortname}\n",
    "\n",
    "# Retrieving all player information from the URL of the JSON file for each match\n",
    "# Récupération de toutes les informations des joueurs à partir de l'url du fichier json de chaque match\n",
    "def build_player_all(match_ids: List[int]) -> pd.DataFrame:\n",
    "    # Link url / Lien url\n",
    "    base_url_tpl = \"https://raw.githubusercontent.com/SkillCorner/opendata/master/data/matches/{mid}/{mid}_match.json\"\n",
    "\n",
    "    # Loop to retrieve each match / Boucle pour récupérer chaque match\n",
    "    rows = []\n",
    "    for mid in match_ids:\n",
    "        url = base_url_tpl.format(mid=mid)\n",
    "        data = _read_json_url(url)\n",
    "        if not data:\n",
    "            continue\n",
    "\n",
    "        team_short_map = {}\n",
    "        ht = data.get(\"home_team\") or {}\n",
    "        at = data.get(\"away_team\") or {}\n",
    "        if \"id\" in ht:\n",
    "            team_short_map[ht[\"id\"]] = ht.get(\"short_name\")\n",
    "        if \"id\" in at:\n",
    "            team_short_map[at[\"id\"]] = at.get(\"short_name\")\n",
    "\n",
    "        players = data.get(\"players\") or []\n",
    "        for p in players:\n",
    "            rec = _normalize_player_record(p, match_id=mid, team_short_map=team_short_map)\n",
    "            if rec is not None:\n",
    "                rows.append(rec)\n",
    "\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"Aucun joueur récupéré depuis les JSONs.\")\n",
    "\n",
    "    player_all = pd.DataFrame(rows)\n",
    "\n",
    "    player_all[\"minutes_played\"] = pd.to_numeric(player_all[\"minutes_played\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    return player_all\n",
    "\n",
    "# Function execution / Execution de la fonction\n",
    "player_all = build_player_all(match_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ab38f-add4-4492-91ce-4d8055b9fec9",
   "metadata": {},
   "source": [
    "### Matches informations / Informations des matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a08c7fba-fdf4-49af-827e-c427c30bae86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] File created / Fichier créé\n"
     ]
    }
   ],
   "source": [
    "# Building a function to retrieve basic information about each match \n",
    "# Construction d'une fonction pour récupérer les informations de base de chaque match\n",
    "def build_match_info_for_competition(url: str,out_dir: str = os.path.join(\"src\", \"data\", \"info_matches\")) -> pd.DataFrame:\n",
    "    data = _read_json_url(url)\n",
    "    if not data:\n",
    "        raise RuntimeError(f\"Aucun match récupéré depuis {url}.\")\n",
    "\n",
    "    matches = pd.DataFrame(data)\n",
    "\n",
    "    if matches.empty:\n",
    "        raise RuntimeError(f\"Aucun match valide dans {url}.\")\n",
    "\n",
    "    # Recovery of competition_edition_id / Récupération de competition_edition_id\n",
    "    competition_edition_id = matches[\"competition_edition_id\"].iloc[0]\n",
    "\n",
    "    # Extracting team information / Extraction des infos d'équipe\n",
    "    def get_team_id(team_dict):\n",
    "        if isinstance(team_dict, dict):\n",
    "            return team_dict.get(\"id\")\n",
    "        return None\n",
    "\n",
    "    def get_team_name(team_dict):\n",
    "        if isinstance(team_dict, dict):\n",
    "            return team_dict.get(\"short_name\")\n",
    "        return None\n",
    "\n",
    "    # Construction of the final dataframe / Construction du dataframe final\n",
    "    out_df = pd.DataFrame({\n",
    "        \"match_id\": matches[\"id\"],\"date_time\": pd.to_datetime(matches[\"date_time\"]).dt.strftime(\"%Y-%m-%d\"),\n",
    "        \"home_team_id\": matches[\"home_team\"].apply(get_team_id),\"home_team_name\": matches[\"home_team\"].apply(get_team_name),\n",
    "        \"away_team_id\": matches[\"away_team\"].apply(get_team_id),\"away_team_name\": matches[\"away_team\"].apply(get_team_name),\n",
    "    })\n",
    "\n",
    "    # Creation of the discharge file / Creation du dossier de sortie\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    out_name = f\"informations_matchs_{competition_edition_id}.csv\"\n",
    "    out_path = os.path.join(out_dir, out_name)\n",
    "\n",
    "    out_df.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(\"[INFO] File created / Fichier créé\")\n",
    "\n",
    "    return out_df\n",
    "\n",
    "# Function execution / Execution de la fonction\n",
    "url_competition = \"https://raw.githubusercontent.com/SkillCorner/opendata/master/data/matches.json\"\n",
    "df_info = build_match_info_for_competition(url_competition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09574b3a-c6c1-4b6b-a0c8-f5b6e272682b",
   "metadata": {},
   "source": [
    "### Calculation of statistics / Calcul des statistiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9621e6-93d0-4e5a-a4c7-1f53cc0f6580",
   "metadata": {},
   "source": [
    "### Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "621e48fa-50d4-417f-ae05-3b16864b88de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update of statistics per match / Mise à jour des statistiques par match\n"
     ]
    }
   ],
   "source": [
    "# List of each subcategory / Liste de chaque sous-catégorie\n",
    "PHASES = [\"build_up\", \"create\", \"finish\", \"direct\", \"quick_break\", \"transition\", \"set_play\", \"chaotic\"]\n",
    "RUN_SUBTYPES   = [\"behind\",\"coming_short\",\"cross_receiver\",\"dropping_off\",\"overlap\",\"pulling_half_space\",\"pulling_wide\",\n",
    "                  \"run_ahead_of_the_ball\",\"support\",\"underlap\"]\n",
    "PRESS_SUBTYPES = [\"pressing\",\"pressure\",\"counter_press\",\"recovery_press\",\"other\"]\n",
    "GAME_STATES    = [\"winning\",\"drawing\",\"loosing\"]\n",
    "SPEED_BANDS_MOVEMENT = [\"jogging\",\"running\",\"hsr\",\"sprinting\"]\n",
    "SPEED_BANDS_RUNS     = [\"running\",\"hsr\",\"sprinting\"]\n",
    "LATERAL = [\"left\",\"center\",\"right\"]\n",
    "THIRDS  = [\"middle_third\",\"attacking_third\"]\n",
    "PENALTY = [\"penalty\"]\n",
    "\n",
    "# Function to retrieve statistics by game / Fonction pour récupérer les statistiques par match\n",
    "def build_match_stats(events_all: pd.DataFrame, out_dir: str = os.path.join(\"src\",\"data\",\"matches\")) -> pd.DataFrame:\n",
    "    # Time sorting / Tri temporel\n",
    "    base = events_all.copy()\n",
    "    time_cols = [c for c in [\"time_end\",\"time_start\"] if c in base.columns]\n",
    "    if time_cols:\n",
    "        base = base.sort_values(time_cols, ascending=True)\n",
    "    elif \"index\" in base.columns:\n",
    "        base = base.sort_values([\"index\"], ascending=True)\n",
    "\n",
    "    # Standardizations / Normalisations\n",
    "    for col in [\"event_subtype\",\"team_in_possession_phase_type\",\"game_state\",\"channel_end\",\"third_end\",\"speed_avg_band\"]:\n",
    "        if col in base.columns:\n",
    "            base[col] = base[col].astype(str).str.lower()\n",
    "    if \"game_state\" in base.columns:\n",
    "        base[\"game_state\"] = base[\"game_state\"].replace({\"losing\":\"loosing\"})\n",
    "\n",
    "    # Mapping zones and speed / Mapping zones et vitesse\n",
    "    def map_lateral(v):\n",
    "        if v == \"center\": return \"center\"\n",
    "        if v in (\"half_space_left\",\"wide_left\"): return \"left\"\n",
    "        if v in (\"half_space_right\",\"wide_right\"): return \"right\"\n",
    "        return None\n",
    "\n",
    "    def map_third(v):\n",
    "        if v in THIRDS: return v\n",
    "        return None\n",
    "\n",
    "    def map_penalty(flag):\n",
    "        try:\n",
    "            return \"penalty\" if bool(flag) else None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def map_speed_move(v):\n",
    "        return v if v in SPEED_BANDS_MOVEMENT else None\n",
    "\n",
    "    def map_speed_run(v):\n",
    "        return v if v in SPEED_BANDS_RUNS else None\n",
    "\n",
    "    # Player informations / Infos joueur\n",
    "    info = (\n",
    "        base[[\"match_id\",\"player_id\",\"player_name\",\"player_position\",\"team_shortname\"]]\n",
    "        .dropna(subset=[\"match_id\",\"player_id\"])\n",
    "        .drop_duplicates(subset=[\"match_id\",\"player_id\"], keep=\"last\")\n",
    "    )\n",
    "\n",
    "    # Helpers pivot\n",
    "    def _pivot_fixed(df_metric: pd.DataFrame, value_col: str, prefix: str, colname: str, buckets: list) -> pd.DataFrame:\n",
    "        if df_metric.empty:\n",
    "            return pd.DataFrame(columns=[\"match_id\",\"player_id\"] + [f\"{prefix}_{b}\" for b in buckets])\n",
    "        wide = (\n",
    "            df_metric.pivot_table(index=[\"match_id\",\"player_id\"], columns=colname, values=value_col,\n",
    "                                  aggfunc=\"sum\", fill_value=0.0).rename_axis(None, axis=1)\n",
    "        )\n",
    "        for b in buckets:\n",
    "            if b not in wide.columns:\n",
    "                wide[b] = 0.0\n",
    "        wide = wide[buckets]\n",
    "        wide.columns = [f\"{prefix}_{b}\" for b in buckets]\n",
    "        return wide.reset_index()\n",
    "\n",
    "    def _pivot_phase(df_metric: pd.DataFrame, value_col: str, prefix: str) -> pd.DataFrame:\n",
    "        return _pivot_fixed(df_metric, value_col, prefix, \"team_in_possession_phase_type\", PHASES)\n",
    "\n",
    "    def _pivot_subtype(df_metric: pd.DataFrame, value_col: str, prefix: str, subtype_list: list, colname: str) -> pd.DataFrame:\n",
    "        return _pivot_fixed(df_metric, value_col, prefix, colname, subtype_list)\n",
    "\n",
    "    def _pivot_state(df_metric: pd.DataFrame, value_col: str, prefix: str) -> pd.DataFrame:\n",
    "        return _pivot_fixed(df_metric, value_col, prefix, \"game_state\", GAME_STATES)\n",
    "\n",
    "    def _pivot_speed_move(df_metric: pd.DataFrame, value_col: str, prefix: str) -> pd.DataFrame:\n",
    "        return _pivot_fixed(df_metric, value_col, prefix, \"speed_avg_band\", SPEED_BANDS_MOVEMENT)\n",
    "\n",
    "    def _pivot_speed_runs(df_metric: pd.DataFrame, value_col: str, prefix: str) -> pd.DataFrame:\n",
    "        return _pivot_fixed(df_metric, value_col, prefix, \"speed_avg_band\", SPEED_BANDS_RUNS)\n",
    "    \n",
    "    # total movement, by phase, by state, by zones, by speed / top_movement global, par phase, par state, par zones, par vitesse\n",
    "    \n",
    "    # Retrieves the value of xthreat and the associated information during an event involving a pass option\n",
    "    # Récupère la valeur de xthreat et les informations associées lors d'un évenement impliquant une option de passe\n",
    "    agg_move = (\n",
    "        base.loc[base[\"event_type\"] == \"passing_option\"]\n",
    "            .groupby([\"match_id\",\"player_id\"])[\"xthreat\"]\n",
    "            .sum().reset_index().rename(columns={\"xthreat\":\"top_movement\"})\n",
    "    )\n",
    "    move_phase = base.loc[base[\"event_type\"] == \"passing_option\",\n",
    "                          [\"match_id\",\"player_id\",\"team_in_possession_phase_type\",\"xthreat\"]] \\\n",
    "                   .dropna(subset=[\"match_id\",\"player_id\",\"team_in_possession_phase_type\"])\n",
    "    agg_move_phase  = move_phase.groupby([\"match_id\",\"player_id\",\"team_in_possession_phase_type\"], as_index=False)[\"xthreat\"].sum() \\\n",
    "                                .rename(columns={\"xthreat\":\"top_movement\"})\n",
    "    wide_move_phase = _pivot_phase(agg_move_phase, \"top_movement\", \"top_movement\")\n",
    "\n",
    "    move_state = base.loc[base[\"event_type\"] == \"passing_option\",\n",
    "                          [\"match_id\",\"player_id\",\"game_state\",\"xthreat\"]] \\\n",
    "                   .dropna(subset=[\"match_id\",\"player_id\",\"game_state\"])\n",
    "    agg_move_state  = move_state.groupby([\"match_id\",\"player_id\",\"game_state\"], as_index=False)[\"xthreat\"].sum() \\\n",
    "                                .rename(columns={\"xthreat\":\"top_movement\"})\n",
    "    wide_move_state = _pivot_state(agg_move_state, \"top_movement\", \"top_movement\")\n",
    "\n",
    "    move_zone = base.loc[base[\"event_type\"] == \"passing_option\",\n",
    "                         [\"match_id\",\"player_id\",\"channel_end\",\"third_end\",\"penalty_area_end\",\"xthreat\"]].copy()\n",
    "    move_zone[\"lateral_zone\"] = move_zone[\"channel_end\"].map(map_lateral)\n",
    "    move_zone[\"third_zone\"]   = move_zone[\"third_end\"].map(map_third)\n",
    "    move_zone[\"pen_zone\"]     = move_zone[\"penalty_area_end\"].map(map_penalty)\n",
    "    wide_move_lat   = _pivot_subtype(move_zone.dropna(subset=[\"lateral_zone\"]), \"xthreat\", \"top_movement\", LATERAL, \"lateral_zone\")\n",
    "    wide_move_third = _pivot_subtype(move_zone.dropna(subset=[\"third_zone\"]),   \"xthreat\", \"top_movement\", THIRDS,  \"third_zone\")\n",
    "    wide_move_pen   = _pivot_subtype(move_zone.dropna(subset=[\"pen_zone\"]),     \"xthreat\", \"top_movement\", PENALTY, \"pen_zone\")\n",
    "\n",
    "    move_speed = base.loc[base[\"event_type\"] == \"passing_option\",\n",
    "                          [\"match_id\",\"player_id\",\"speed_avg_band\",\"xthreat\"]].copy()\n",
    "    move_speed[\"speed_avg_band\"] = move_speed[\"speed_avg_band\"].map(map_speed_move)\n",
    "    wide_move_speed = _pivot_speed_move(move_speed.dropna(subset=[\"speed_avg_band\"]), \"xthreat\", \"top_movement\")\n",
    "\n",
    "    # top_off_ball_runs overall, by phase, by subtype, by state, by zone, by speed\n",
    "    # top_off_ball_runs global, par phase, par subtype, par state, par zones, par vitesse\n",
    "\n",
    "    # Retrieves the value of xthreat and the associated information during an event involving a off ball run\n",
    "    # Récupère la valeur de xthreat et les informations associées lors d'un évenement impliquant une course sans ballon\n",
    "    agg_run = (\n",
    "        base.loc[base[\"event_type\"] == \"off_ball_run\"]\n",
    "            .groupby([\"match_id\",\"player_id\"])[\"xthreat\"]\n",
    "            .sum().reset_index().rename(columns={\"xthreat\":\"top_off_ball_runs\"})\n",
    "    )\n",
    "    run_phase = base.loc[base[\"event_type\"] == \"off_ball_run\",\n",
    "                         [\"match_id\",\"player_id\",\"team_in_possession_phase_type\",\"xthreat\"]] \\\n",
    "                .dropna(subset=[\"match_id\",\"player_id\",\"team_in_possession_phase_type\"])\n",
    "    agg_run_phase  = run_phase.groupby([\"match_id\",\"player_id\",\"team_in_possession_phase_type\"], as_index=False)[\"xthreat\"].sum() \\\n",
    "                              .rename(columns={\"xthreat\":\"top_off_ball_runs\"})\n",
    "    wide_run_phase = _pivot_phase(agg_run_phase, \"top_off_ball_runs\", \"top_off_ball_runs\")\n",
    "\n",
    "    run_subtype = base.loc[(base[\"event_type\"] == \"off_ball_run\") & (base[\"event_subtype\"].isin(RUN_SUBTYPES)),\n",
    "                           [\"match_id\",\"player_id\",\"event_subtype\",\"xthreat\"]] \\\n",
    "                 .dropna(subset=[\"match_id\",\"player_id\",\"event_subtype\"])\n",
    "    agg_run_subtype  = run_subtype.groupby([\"match_id\",\"player_id\",\"event_subtype\"], as_index=False)[\"xthreat\"].sum() \\\n",
    "                                   .rename(columns={\"xthreat\":\"top_off_ball_runs\"})\n",
    "    wide_run_subtype = _pivot_subtype(agg_run_subtype, \"top_off_ball_runs\", \"top_off_ball_runs\", RUN_SUBTYPES, \"event_subtype\")\n",
    "\n",
    "    run_state = base.loc[base[\"event_type\"] == \"off_ball_run\",\n",
    "                         [\"match_id\",\"player_id\",\"game_state\",\"xthreat\"]] \\\n",
    "               .dropna(subset=[\"match_id\",\"player_id\",\"game_state\"])\n",
    "    agg_run_state  = run_state.groupby([\"match_id\",\"player_id\",\"game_state\"], as_index=False)[\"xthreat\"].sum() \\\n",
    "                              .rename(columns={\"xthreat\":\"top_off_ball_runs\"})\n",
    "    wide_run_state = _pivot_state(agg_run_state, \"top_off_ball_runs\", \"top_off_ball_runs\")\n",
    "\n",
    "    run_zone = base.loc[base[\"event_type\"] == \"off_ball_run\",\n",
    "                        [\"match_id\",\"player_id\",\"channel_end\",\"third_end\",\"penalty_area_end\",\"xthreat\"]].copy()\n",
    "    run_zone[\"lateral_zone\"] = run_zone[\"channel_end\"].map(map_lateral)\n",
    "    run_zone[\"third_zone\"]   = run_zone[\"third_end\"].map(map_third)\n",
    "    run_zone[\"pen_zone\"]     = run_zone[\"penalty_area_end\"].map(map_penalty)\n",
    "    wide_run_lat   = _pivot_subtype(run_zone.dropna(subset=[\"lateral_zone\"]), \"xthreat\", \"top_off_ball_runs\", LATERAL, \"lateral_zone\")\n",
    "    wide_run_third = _pivot_subtype(run_zone.dropna(subset=[\"third_zone\"]),   \"xthreat\", \"top_off_ball_runs\", THIRDS,  \"third_zone\")\n",
    "    wide_run_pen   = _pivot_subtype(run_zone.dropna(subset=[\"pen_zone\"]),     \"xthreat\", \"top_off_ball_runs\", PENALTY, \"pen_zone\")\n",
    "\n",
    "    run_speed = base.loc[base[\"event_type\"] == \"off_ball_run\",\n",
    "                         [\"match_id\",\"player_id\",\"speed_avg_band\",\"xthreat\"]].copy()\n",
    "    run_speed[\"speed_avg_band\"] = run_speed[\"speed_avg_band\"].map(map_speed_run)\n",
    "    wide_run_speed = _pivot_speed_runs(run_speed.dropna(subset=[\"speed_avg_band\"]), \"xthreat\", \"top_off_ball_runs\")\n",
    "\n",
    "    # top_choice global, by state, by zones / top_choice global, par state, par zones\n",
    "    # top_choice en pourcentage: global, par state, par zones, par phase\n",
    "\n",
    "    # We calculate the percentage of correct choices made by each player in relation to the possible pass options (more than two)\n",
    "    # and the xthreat value. We also collect information associated with this choice.\n",
    "    # On calcule le pourcentage de bon choix effectué par joueur au regard des options de passes possible (au delà de 2),\n",
    "    # et de la valeur du xthreat. On récupère également les informations associées à ce choix.\n",
    "    def is_pivot(row) -> bool:\n",
    "        return (\n",
    "            row.get(\"event_type\") == \"player_possession\"\n",
    "            and row.get(\"end_type\") == \"pass\"\n",
    "            and float(row.get(\"player_targeted_xthreat\", 0.0)) > 0.0\n",
    "        )\n",
    "    \n",
    "    rows_global = []\n",
    "    rows_state  = []\n",
    "    rows_lat    = []\n",
    "    rows_third  = []\n",
    "    rows_pen    = []\n",
    "    rows_phase  = []\n",
    "    \n",
    "    EPS = 1e-12\n",
    "    \n",
    "    for mid, dfm in base.groupby(\"match_id\", sort=False):\n",
    "        dfm = dfm.reset_index(drop=True)\n",
    "    \n",
    "        current_actor_id = None\n",
    "        chosen_target_id = None\n",
    "        chosen_target_name = None\n",
    "        chosen_x = None\n",
    "        current_state = None\n",
    "        current_phase = None\n",
    "    \n",
    "        chosen_lat = None\n",
    "        chosen_thd = None\n",
    "        chosen_pen = None\n",
    "    \n",
    "        options_any = [] \n",
    "    \n",
    "        def push_decision():\n",
    "            # Validates a decision if at least 2 options in total / Valide une décision si au moins 2 options au total\n",
    "            if (current_actor_id is None) or (chosen_x is None):\n",
    "                return\n",
    "            total_opts = 1 + len(options_any)\n",
    "            if total_opts < 2:\n",
    "                # no attempt if only one option / pas de tentative si une seule option\n",
    "                return\n",
    "            best_other = float(np.max(options_any)) if len(options_any) > 0 else -np.inf\n",
    "            success = 1 if (chosen_x + EPS >= best_other) else 0\n",
    "            attempt = 1\n",
    "    \n",
    "            rows_global.append((mid, current_actor_id, success, attempt))\n",
    "            if current_state is not None:\n",
    "                rows_state.append((mid, current_actor_id, current_state, success, attempt))\n",
    "            if chosen_lat is not None:\n",
    "                rows_lat.append((mid, current_actor_id, chosen_lat, success, attempt))\n",
    "            if chosen_thd is not None:\n",
    "                rows_third.append((mid, current_actor_id, chosen_thd, success, attempt))\n",
    "            if chosen_pen is not None:\n",
    "                rows_pen.append((mid, current_actor_id, chosen_pen, success, attempt))\n",
    "            if current_phase is not None:\n",
    "                rows_phase.append((mid, current_actor_id, current_phase, success, attempt))\n",
    "                \n",
    "        # We compare the possible pass options, memorising the passer's choice.\n",
    "        # On compare les options de passes possibles, en mémorisant le choix du passeur\n",
    "        for _, row in dfm.iterrows():\n",
    "            if is_pivot(row):\n",
    "                push_decision()\n",
    "                current_actor_id   = row[\"player_id\"]\n",
    "                chosen_x           = float(row[\"player_targeted_xthreat\"])\n",
    "                chosen_target_id   = row.get(\"player_targeted_id\")\n",
    "                chosen_target_name = row.get(\"player_targeted_name\")\n",
    "                current_state      = row.get(\"game_state\")\n",
    "                current_phase      = row.get(\"team_in_possession_phase_type\")  # nouveau\n",
    "                chosen_lat = None; chosen_thd = None; chosen_pen = None\n",
    "                options_any = []\n",
    "                continue\n",
    "    \n",
    "            if (current_actor_id is not None) and (chosen_x is not None):\n",
    "                if row.get(\"event_type\") == \"passing_option\":\n",
    "                    opt_tid   = row.get(\"player_targeted_id\")\n",
    "                    opt_tname = row.get(\"player_targeted_name\")\n",
    "                    xv        = float(row.get(\"xthreat\", 0.0))\n",
    "    \n",
    "                    is_chosen = False\n",
    "                    if pd.notna(opt_tid) and pd.notna(chosen_target_id):\n",
    "                        is_chosen = (opt_tid == chosen_target_id)\n",
    "                    if (not is_chosen) and isinstance(opt_tname, str) and isinstance(chosen_target_name, str):\n",
    "                        is_chosen = (opt_tname == chosen_target_name)\n",
    "                    if (not is_chosen) and abs(xv - chosen_x) <= EPS:\n",
    "                        is_chosen = True\n",
    "    \n",
    "                    if is_chosen:\n",
    "                        # the selected pass area is memorised / on mémorise la zone de la passe choisie\n",
    "                        chosen_lat = map_lateral(row.get(\"channel_end\"))\n",
    "                        chosen_thd = map_third(row.get(\"third_end\"))\n",
    "                        chosen_pen = map_penalty(row.get(\"penalty_area_end\"))\n",
    "                    else:\n",
    "                        options_any.append(xv)\n",
    "        push_decision()\n",
    "        \n",
    "    # We calculate the percentage of correct choices made on the match, as well as the total number of choices.\n",
    "    # On calcule le pourcentage de bon choix effectué sur le match, ainsi que le nombre de choix au total.\n",
    "    def _to_pct_global(rows):\n",
    "        if not rows:\n",
    "            return pd.DataFrame(columns=[\"match_id\",\"player_id\",\"top_choice\",\"top_choice_attempts\"])\n",
    "        df = pd.DataFrame(rows, columns=[\"match_id\",\"player_id\",\"success\",\"attempt\"])\n",
    "        agg = df.groupby([\"match_id\",\"player_id\"], as_index=False)[[\"success\",\"attempt\"]].sum()\n",
    "        agg[\"top_choice\"] = np.where(agg[\"attempt\"] > 0, agg[\"success\"] / agg[\"attempt\"], 0.0)\n",
    "        agg[\"top_choice_attempts\"] = agg[\"attempt\"]\n",
    "        return agg[[\"match_id\",\"player_id\",\"top_choice\",\"top_choice_attempts\"]]\n",
    "\n",
    "    \n",
    "    def _to_pct_bucket(rows, bucket_col_name, prefix):\n",
    "        if not rows:\n",
    "            return pd.DataFrame(columns=[\"match_id\",\"player_id\"])\n",
    "        df = pd.DataFrame(rows, columns=[\"match_id\",\"player_id\",bucket_col_name,\"success\",\"attempt\"])\n",
    "        agg = df.groupby([\"match_id\",\"player_id\",bucket_col_name], as_index=False)[[\"success\",\"attempt\"]].sum()\n",
    "        agg[\"top_choice\"] = np.where(agg[\"attempt\"] > 0, agg[\"success\"] / agg[\"attempt\"], 0.0)\n",
    "\n",
    "        pct_df = agg.rename(columns={\"top_choice\": \"value\"})\n",
    "        att_df = agg.rename(columns={\"attempt\": \"value\"})\n",
    "\n",
    "        if bucket_col_name == \"game_state\":\n",
    "            wide_pct = _pivot_state(pct_df, \"value\", \"top_choice\")\n",
    "            wide_att = _pivot_state(att_df, \"value\", \"top_choice_attempts\")\n",
    "        elif bucket_col_name == \"lateral\":\n",
    "            wide_pct = _pivot_subtype(pct_df, \"value\", \"top_choice\", LATERAL, \"lateral\")\n",
    "            wide_att = _pivot_subtype(att_df, \"value\", \"top_choice_attempts\", LATERAL, \"lateral\")\n",
    "        elif bucket_col_name == \"third\":\n",
    "            wide_pct = _pivot_subtype(pct_df, \"value\", \"top_choice\", THIRDS, \"third\")\n",
    "            wide_att = _pivot_subtype(att_df, \"value\", \"top_choice_attempts\", THIRDS, \"third\")\n",
    "        elif bucket_col_name == \"pen\":\n",
    "            wide_pct = _pivot_subtype(pct_df, \"value\", \"top_choice\", PENALTY, \"pen\")\n",
    "            wide_att = _pivot_subtype(att_df, \"value\", \"top_choice_attempts\", PENALTY, \"pen\")\n",
    "        elif bucket_col_name == \"team_in_possession_phase_type\":\n",
    "            wide_pct = _pivot_phase(pct_df, \"value\", \"top_choice\")\n",
    "            wide_att = _pivot_phase(att_df, \"value\", \"top_choice_attempts\")\n",
    "        else:\n",
    "            return pd.DataFrame(columns=[\"match_id\",\"player_id\"])\n",
    "\n",
    "        wide = wide_pct.merge(wide_att, on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "        return wide\n",
    "\n",
    "    # Finals tables / Tables finales\n",
    "    tc_df            = _to_pct_global(rows_global)\n",
    "    wide_choice_state= _to_pct_bucket(rows_state,  \"game_state\", \"top_choice\")\n",
    "    wide_choice_lat  = _to_pct_bucket(rows_lat,    \"lateral\",\"top_choice\")\n",
    "    wide_choice_third= _to_pct_bucket(rows_third,  \"third\",\"top_choice\")\n",
    "    wide_choice_pen  = _to_pct_bucket(rows_pen,    \"pen\",\"top_choice\")\n",
    "    wide_choice_phase= _to_pct_bucket(rows_phase,  \"team_in_possession_phase_type\", \"top_choice\")\n",
    "\n",
    "    # top_press global, by subtype, and by phase of play / top_press global, par subtype, et par phase de jeu\n",
    "\n",
    "    # We recover the influence of the pressure exerted by the player on the danger of the opposing action and related information\n",
    "    # On récupère l'influence de la pression émise par le joueur sur le danger de l'action adverse et les informations associées\n",
    "    press = base.loc[base.get(\"possession_danger\", False) == True].copy()\n",
    "    if not press.empty:\n",
    "        b_bp  = press[\"beaten_by_possession\"].fillna(False)\n",
    "        b_bm  = press[\"beaten_by_movement\"].fillna(False)\n",
    "        b_red = press[\"reduce_possession_danger\"].fillna(False)\n",
    "        b_aff = press[\"affected_line_breaking_passing_option_dangerous\"].fillna(False)\n",
    "        b_stp = press[\"stop_possession_danger\"].fillna(False)\n",
    "\n",
    "        Penaltie      = np.where((b_bp | b_bm), -0.5, 0.0)\n",
    "        little_bonus  = np.where((b_red | b_aff),  0.5, 0.0)\n",
    "        bonus         = np.where(b_stp,            1, 0.0)\n",
    "        is_neutral    = (~(b_bp | b_bm | b_red | b_aff | b_stp)).astype(bool)\n",
    "        neutral_bonus = np.where(is_neutral,       0.25, 0.0)\n",
    "\n",
    "        press[\"press_score\"] = Penaltie + little_bonus + bonus + neutral_bonus\n",
    "\n",
    "        agg_press = press.groupby([\"match_id\",\"player_id\"])[\"press_score\"].sum().reset_index().rename(columns={\"press_score\":\"top_press\"})\n",
    "\n",
    "        press_subtype = press.loc[press[\"event_subtype\"].isin(PRESS_SUBTYPES),\n",
    "                                  [\"match_id\",\"player_id\",\"event_subtype\",\"press_score\"]].dropna(subset=[\"match_id\",\"player_id\",\"event_subtype\"])\n",
    "        agg_press_subtype  = press_subtype.groupby([\"match_id\",\"player_id\",\"event_subtype\"], as_index=False)[\"press_score\"].sum() \\\n",
    "                                         .rename(columns={\"press_score\":\"top_press\"})\n",
    "        wide_press_subtype = _pivot_subtype(agg_press_subtype, \"top_press\", \"top_press\", PRESS_SUBTYPES, \"event_subtype\")\n",
    "\n",
    "        press_state = press.loc[press[\"game_state\"].isin(GAME_STATES),\n",
    "                                [\"match_id\",\"player_id\",\"game_state\",\"press_score\"]].dropna(subset=[\"match_id\",\"player_id\",\"game_state\"])\n",
    "        agg_press_state  = press_state.groupby([\"match_id\",\"player_id\",\"game_state\"], as_index=False)[\"press_score\"].sum() \\\n",
    "                                       .rename(columns={\"press_score\":\"top_press\"})\n",
    "        wide_press_state = _pivot_state(agg_press_state, \"top_press\", \"top_press\")\n",
    "    else:\n",
    "        agg_press = pd.DataFrame(columns=[\"match_id\",\"player_id\",\"top_press\"])\n",
    "        wide_press_subtype = pd.DataFrame(columns=[\"match_id\",\"player_id\"] + [f\"top_press_{s}\" for s in PRESS_SUBTYPES])\n",
    "        wide_press_state   = pd.DataFrame(columns=[\"match_id\",\"player_id\"] + [f\"top_press_{s}\" for s in GAME_STATES])\n",
    "\n",
    "    # Merge / Fusion\n",
    "    result_global = (\n",
    "        agg_move.merge(agg_run,  on=[\"match_id\",\"player_id\"], how=\"outer\")\n",
    "                .merge(tc_df,    on=[\"match_id\",\"player_id\"], how=\"outer\")\n",
    "                .merge(agg_press,on=[\"match_id\",\"player_id\"], how=\"outer\")\n",
    "    )\n",
    "\n",
    "    result = (\n",
    "        info.merge(result_global,       on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            # movement\n",
    "            .merge(wide_move_phase,     on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_move_state,     on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_move_lat,       on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_move_third,     on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_move_pen,       on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_move_speed,     on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            # runs\n",
    "            .merge(wide_run_phase,      on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_run_subtype,    on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_run_state,      on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_run_lat,        on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_run_third,      on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_run_pen,        on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_run_speed,      on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            # choice\n",
    "            .merge(wide_choice_phase,  on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_choice_state,   on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_choice_lat,     on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_choice_third,   on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_choice_pen,     on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "\n",
    "            # press\n",
    "            .merge(wide_press_subtype,  on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "            .merge(wide_press_state,    on=[\"match_id\",\"player_id\"], how=\"left\")\n",
    "    )\n",
    "\n",
    "    # Filling and rounding / Remplissage et arrondis\n",
    "    metric_cols = [col for col in result.columns if col not in [\"match_id\",\"player_id\",\"player_name\",\"player_position\",\"team_shortname\"]]\n",
    "    for c in metric_cols:\n",
    "        result[c] = pd.to_numeric(result[c], errors=\"coerce\").fillna(0.0).astype(float).round(2)\n",
    "\n",
    "    # Final columns / Colonnes finales\n",
    "    cols_m_phase  = [f\"top_movement_{p}\" for p in PHASES if f\"top_movement_{p}\" in result.columns]\n",
    "    cols_c_phase = [f\"top_choice_{p}\" for p in PHASES if f\"top_choice_{p}\" in result.columns]\n",
    "    cols_c_attempts_phase = [f\"top_choice_attempts_{p}\" for p in PHASES      if f\"top_choice_attempts_{p}\" in result.columns]\n",
    "    cols_r_phase  = [f\"top_off_ball_runs_{p}\" for p in PHASES if f\"top_off_ball_runs_{p}\" in result.columns]\n",
    "    cols_r_sub    = [f\"top_off_ball_runs_{s}\" for s in RUN_SUBTYPES if f\"top_off_ball_runs_{s}\" in result.columns]\n",
    "    cols_p_sub    = [f\"top_press_{s}\" for s in PRESS_SUBTYPES if f\"top_press_{s}\" in result.columns]\n",
    "    cols_m_state  = [f\"top_movement_{s}\" for s in GAME_STATES if f\"top_movement_{s}\" in result.columns]\n",
    "    cols_r_state  = [f\"top_off_ball_runs_{s}\" for s in GAME_STATES if f\"top_off_ball_runs_{s}\" in result.columns]\n",
    "    cols_c_state  = [f\"top_choice_{s}\" for s in GAME_STATES if f\"top_choice_{s}\" in result.columns]\n",
    "    cols_c_attempts_state = [f\"top_choice_attempts_{s}\" for s in GAME_STATES if f\"top_choice_attempts_{s}\" in result.columns]\n",
    "    cols_p_state  = [f\"top_press_{s}\" for s in GAME_STATES if f\"top_press_{s}\" in result.columns]\n",
    "    cols_m_lat    = [f\"top_movement_{b}\" for b in LATERAL if f\"top_movement_{b}\" in result.columns]\n",
    "    cols_m_thd    = [f\"top_movement_{b}\" for b in THIRDS  if f\"top_movement_{b}\" in result.columns]\n",
    "    cols_m_pen    = [\"top_movement_penalty\"] if \"top_movement_penalty\" in result.columns else []\n",
    "    cols_r_lat    = [f\"top_off_ball_runs_{b}\" for b in LATERAL if f\"top_off_ball_runs_{b}\" in result.columns]\n",
    "    cols_r_thd    = [f\"top_off_ball_runs_{b}\" for b in THIRDS  if f\"top_off_ball_runs_{b}\" in result.columns]\n",
    "    cols_r_pen    = [\"top_off_ball_runs_penalty\"] if \"top_off_ball_runs_penalty\" in result.columns else []\n",
    "    cols_c_lat    = [f\"top_choice_{b}\" for b in LATERAL if f\"top_choice_{b}\" in result.columns]\n",
    "    cols_c_attempts_lat   = [f\"top_choice_attempts_{b}\" for b in LATERAL     if f\"top_choice_attempts_{b}\" in result.columns]\n",
    "    cols_c_thd    = [f\"top_choice_{b}\" for b in THIRDS  if f\"top_choice_{b}\" in result.columns]\n",
    "    cols_c_attempts_thd   = [f\"top_choice_attempts_{b}\" for b in THIRDS      if f\"top_choice_attempts_{b}\" in result.columns]\n",
    "    cols_c_pen    = [\"top_choice_penalty\"] if \"top_choice_penalty\" in result.columns else []\n",
    "    cols_c_attempts_pen   = [\"top_choice_attempts_penalty\"] if \"top_choice_attempts_penalty\" in result.columns else []\n",
    "    cols_m_spd    = [f\"top_movement_{b}\" for b in SPEED_BANDS_MOVEMENT if f\"top_movement_{b}\" in result.columns]\n",
    "    cols_r_spd    = [f\"top_off_ball_runs_{b}\" for b in SPEED_BANDS_RUNS if f\"top_off_ball_runs_{b}\" in result.columns]\n",
    "\n",
    "    # We sort the list of columns / On ordonne la liste de colonnes\n",
    "    ordered_cols = [\n",
    "        \"player_id\",\"player_name\",\"player_position\",\"team_shortname\",\n",
    "        \"top_movement\",\"top_off_ball_runs\",\"top_choice\",\"top_choice_attempts\",\"top_press\",\n",
    "        *cols_m_phase, *cols_r_phase, *cols_r_sub, *cols_p_sub,\n",
    "        *cols_m_state, *cols_r_state, *cols_c_state, *cols_c_attempts_state, *cols_p_state,\n",
    "        *cols_m_lat, *cols_m_thd, *cols_m_pen,\n",
    "        *cols_r_lat, *cols_r_thd, *cols_r_pen,\n",
    "        *cols_c_lat, *cols_c_attempts_lat,\n",
    "        *cols_c_thd, *cols_c_attempts_thd,\n",
    "        *cols_c_pen, *cols_c_attempts_pen,\n",
    "        *cols_c_phase, *cols_c_attempts_phase,\n",
    "        *cols_m_spd, *cols_r_spd,\n",
    "        \"match_id\",\n",
    "    ]\n",
    "    ordered_cols = [c for c in ordered_cols if c in result.columns]\n",
    "    result = result[ordered_cols]\n",
    "\n",
    "    # Save per match / Sauvegarde par match\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for mid, sub in result.groupby(\"match_id\"):\n",
    "        out_path = os.path.join(out_dir, f\"{int(mid)}_stats.csv\")\n",
    "        sub_out = sub.drop(columns=[\"match_id\"], errors=\"ignore\").sort_values(\n",
    "            [c for c in [\"top_choice\",\"top_press\",\"top_movement\",\"top_off_ball_runs\"] if c in sub.columns] or [\"player_name\"],\n",
    "            ascending=False\n",
    "        )\n",
    "        sub_out.to_csv(out_path, index=False)\n",
    "\n",
    "    print(\"Update of statistics per match / Mise à jour des statistiques par match\")\n",
    "    return result\n",
    "\n",
    "# Function execution / Execution de la fonction\n",
    "result_df = build_match_stats(events_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75e0cbb-f02d-41bb-ad1d-dd9054bf4f2e",
   "metadata": {},
   "source": [
    "### Équipes / Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0775eb51-0735-4e6f-a5af-367527510f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written team table / Table équipes écrite\n"
     ]
    }
   ],
   "source": [
    "# Aggregate statistics by team / Aggrége les statistiques par équipe\n",
    "def build_team_stats_table(match_dir: str = os.path.join(\"src\", \"data\", \"matches\"),out_dir: str = os.path.join(\"src\", \"data\", \"teams\"),\n",
    "    out_name: str = \"team.csv\") -> pd.DataFrame:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    pattern = re.compile(r\"(\\d+)_stats\\.csv$\")\n",
    "    files = sorted(glob.glob(os.path.join(match_dir, \"*_stats.csv\")))\n",
    "    if not files:\n",
    "        print(\"No _stats.csv file found / Aucun fichier _stats.csv trouvé.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    frames = []\n",
    "    for fp in files:\n",
    "        try:\n",
    "            df = pd.read_csv(fp)\n",
    "            # Add match_id from the file name if not available / Ajouter match_id depuis le nom de fichier si absent\n",
    "            if \"match_id\" not in df.columns:\n",
    "                m = pattern.search(os.path.basename(fp))\n",
    "                if m:\n",
    "                    df = df.copy()\n",
    "                    df[\"match_id\"] = int(m.group(1))\n",
    "                else:\n",
    "                    print(f\"Unrecognised file name, ignored / Nom de fichier non reconnu, ignoré: {fp}\")\n",
    "                    continue\n",
    "            if {\"team_shortname\", \"match_id\"}.issubset(df.columns):\n",
    "                frames.append(df)\n",
    "            else:\n",
    "                print(f\"Missing columns in / Colonnes manquantes dans {fp}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Reading error / Erreur lecture {fp}: {e}\")\n",
    "\n",
    "    if not frames:\n",
    "        print(\"No usable data / Aucune donnée exploitable.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = pd.concat(frames, ignore_index=True)\n",
    "    data = data.dropna(subset=[\"team_shortname\", \"match_id\"])\n",
    "    for c in data.columns:\n",
    "        if c not in {\"team_shortname\"}:\n",
    "            data[c] = pd.to_numeric(data[c], errors=\"ignore\")\n",
    "\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    exclude_cols = {\"match_id\", \"player_id\"}\n",
    "    metric_cols = [c for c in numeric_cols if c not in exclude_cols]\n",
    "    if not metric_cols:\n",
    "        print(\"No digital metric column found / Aucune colonne de métrique numérique trouvée.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Team total in each match / Somme par équipe dans chaque match\n",
    "    per_match_team = (\n",
    "        data.groupby([\"team_shortname\", \"match_id\"], as_index=False)[metric_cols]\n",
    "            .sum()\n",
    "    )\n",
    "\n",
    "    top_choice_cols = [\n",
    "        c for c in metric_cols\n",
    "        if c.startswith(\"top_choice\") and not c.startswith(\"top_choice_attempts\")\n",
    "    ]\n",
    "\n",
    "    # We construct the pairs (top_choice_xxx, top_choice_attempts_xxx) / On construit les paires (top_choice_xxx, top_choice_attempts_xxx) \n",
    "    pairs = []\n",
    "    for col in top_choice_cols:\n",
    "        suffix = col[len(\"top_choice\"):]  # \"\", \"_winning\", \"_left\", etc.\n",
    "        att_col = \"top_choice_attempts\" + suffix\n",
    "        if att_col in metric_cols:\n",
    "            pairs.append((col, att_col))\n",
    "\n",
    "    if pairs:\n",
    "        weighted_df = None\n",
    "\n",
    "        for col, att_col in pairs:\n",
    "            # For each match and team: attempts_tot and a weighted rate are calculated.\n",
    "            # Pour chaque match et équipe: on calcule attempts_tot et un taux pondéré\n",
    "            tmp = (\n",
    "                data.groupby([\"team_shortname\", \"match_id\"])[[col, att_col]]\n",
    "                    .apply(\n",
    "                        lambda g: pd.Series({\n",
    "                            col: (g[col] * g[att_col]).sum() / g[att_col].sum()\n",
    "                                 if g[att_col].sum() > 0 else 0.0,\n",
    "                            att_col: g[att_col].sum()\n",
    "                        })\n",
    "                    )\n",
    "                    .reset_index()\n",
    "            )\n",
    "\n",
    "            if weighted_df is None:\n",
    "                weighted_df = tmp\n",
    "            else:\n",
    "                weighted_df = weighted_df.merge(tmp, on=[\"team_shortname\", \"match_id\"], how=\"outer\")\n",
    "\n",
    "        # In per_match_team, the values of top_choice and top_choice_attempts are replaced by these weighted values.\n",
    "        # On remplace dans per_match_team les valeurs de top_choice et top_choice_attempts par ces valeurs pondérées\n",
    "        if weighted_df is not None:\n",
    "            drop_cols = []\n",
    "            for col, att_col in pairs:\n",
    "                if col in per_match_team.columns:\n",
    "                    drop_cols.append(col)\n",
    "                if att_col in per_match_team.columns:\n",
    "                    drop_cols.append(att_col)\n",
    "            drop_cols = list(set(drop_cols))\n",
    "\n",
    "            per_match_team = (\n",
    "                per_match_team.drop(columns=drop_cols, errors=\"ignore\")\n",
    "                              .merge(weighted_df, on=[\"team_shortname\", \"match_id\"], how=\"left\")\n",
    "            )\n",
    "\n",
    "    # Number of matches played per team / Nombre de matchs joués par équipe\n",
    "    match_played = (\n",
    "        per_match_team.groupby(\"team_shortname\", as_index=False)[\"match_id\"]\n",
    "            .nunique()\n",
    "            .rename(columns={\"match_id\": \"match_played\"})\n",
    "    )\n",
    "\n",
    "    # Average per match team statistics / Moyenne par match des stats d'équipe\n",
    "    team_means = (\n",
    "        per_match_team.groupby(\"team_shortname\", as_index=False)[metric_cols]\n",
    "            .mean()\n",
    "    )\n",
    "\n",
    "    # Final mergers / Fusion finales\n",
    "    team_table = team_means.merge(match_played, on=\"team_shortname\", how=\"left\")\n",
    "\n",
    "    # Creating id_team from the name / Création id_team à partir du nom\n",
    "    team_table.insert(\n",
    "        0,\n",
    "        \"id_team\",\n",
    "        team_table[\"team_shortname\"].apply(\n",
    "            lambda x: int(sha1(str(x).encode()).hexdigest(), 16) % (10**8)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Types and rounding / Types et arrondis\n",
    "    for c in team_table.columns:\n",
    "        if c == \"match_played\":\n",
    "            team_table[c] = team_table[c].astype(int)\n",
    "        elif c not in {\"id_team\", \"team_shortname\"}:\n",
    "            team_table[c] = pd.to_numeric(team_table[c], errors=\"coerce\").fillna(0.0).round(2)\n",
    "\n",
    "    out_path = os.path.join(out_dir, out_name)\n",
    "    team_table.to_csv(out_path, index=False)\n",
    "    print(\"Written team table / Table équipes écrite\")\n",
    "    return team_table\n",
    "\n",
    "# Function execution / Execution de la fonction\n",
    "teams_df = build_team_stats_table()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8451f4d-bd97-478a-be98-ce4ecafae981",
   "metadata": {},
   "source": [
    "### Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "152e2db7-a636-4df3-83d0-a4b454ecea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player table written / Table joueurs écrite\n"
     ]
    }
   ],
   "source": [
    "# Aggregation of player statistics / Agrégation des statistiques des joueurs\n",
    "def build_players_table(result_df: pd.DataFrame,player_all: pd.DataFrame,out_dir: str = os.path.join(\"src\", \"data\", \"players\"),\n",
    "    out_name: str = \"player.csv\",per90: bool = True) -> pd.DataFrame:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    id_cols = [\"player_id\", \"player_name\", \"player_position\", \"team_shortname\", \"match_id\"]\n",
    "\n",
    "    # We collect statistics per player / On récupère les statistiques par joueur\n",
    "    left_keep  = [c for c in id_cols if c in result_df.columns]\n",
    "    right_keep = [\"match_id\", \"player_id\", \"minutes_played\",\n",
    "                  \"team_shortname_json\", \"player_name_json\", \"player_position_json\"]\n",
    "\n",
    "    merged = result_df[left_keep].merge(\n",
    "        player_all[right_keep],\n",
    "        on=[\"match_id\", \"player_id\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    metric_cols = [\n",
    "        c for c in result_df.columns\n",
    "        if c not in {\"match_id\",\"player_id\",\"player_name\",\"player_position\",\"team_shortname\"}\n",
    "    ]\n",
    "    metric_cols = [c for c in metric_cols if pd.api.types.is_numeric_dtype(result_df[c])]\n",
    "\n",
    "    # Data Merge / Fusion des données\n",
    "    merged = merged.merge(\n",
    "        result_df[[\"match_id\",\"player_id\"] + metric_cols],\n",
    "        on=[\"match_id\",\"player_id\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Replacing missing values / On remplace les valeurs manquantes\n",
    "    merged[\"player_name\"] = merged[\"player_name\"].fillna(merged[\"player_name_json\"])\n",
    "    merged[\"player_position\"] = merged[\"player_position\"].fillna(merged[\"player_position_json\"])\n",
    "    merged[\"team_shortname\"] = merged[\"team_shortname\"].fillna(merged[\"team_shortname_json\"])\n",
    "    merged[\"minutes_played\"] = pd.to_numeric(merged[\"minutes_played\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    # Keys for aggregation / Clés d'agrégation\n",
    "    group_keys = [\"player_id\",\"player_name\",\"player_position\",\"team_shortname\"]\n",
    "\n",
    "    # Matches played / Matchs joués\n",
    "    match_played = (\n",
    "        merged.loc[merged[\"minutes_played\"] > 0]\n",
    "              .groupby(group_keys, as_index=False)[\"match_id\"].nunique()\n",
    "              .rename(columns={\"match_id\":\"match_played\"})\n",
    "    )\n",
    "\n",
    "    # Total minutes / Minutes totales\n",
    "    minutes_total = (\n",
    "        merged.groupby(group_keys, as_index=False)[\"minutes_played\"]\n",
    "              .sum()\n",
    "              .rename(columns={\"minutes_played\":\"minutes_total\"})\n",
    "    )\n",
    "\n",
    "    # top_choice categories\n",
    "    pct_cols      = [c for c in metric_cols if c.startswith(\"top_choice\") and not c.startswith(\"top_choice_attempts\")]\n",
    "    attempts_cols = [c for c in metric_cols if c.startswith(\"top_choice_attempts\")]\n",
    "    other_cols    = [c for c in metric_cols if c not in pct_cols + attempts_cols]\n",
    "\n",
    "    # Sum for non-choice metrics / Somme pour métriques hors top_choice\n",
    "    agg_other = merged.groupby(group_keys, as_index=False)[other_cols].sum() if other_cols else merged[group_keys].drop_duplicates()\n",
    "\n",
    "    # Weighted top_choice and average attempts / top_choice pondéré et attempts moyens\n",
    "    from functools import reduce\n",
    "    frames_choice = []\n",
    "\n",
    "    # Pair (pct, attempts) / Paires (pct, attempts)\n",
    "    pairs = []\n",
    "    for pct in pct_cols:\n",
    "        suffix = pct[len(\"top_choice\"):]\n",
    "        att = \"top_choice_attempts\" + suffix\n",
    "        if att in attempts_cols:\n",
    "            pairs.append((pct, att))\n",
    "\n",
    "    for pct_col, att_col in pairs:\n",
    "        tmp = (\n",
    "            merged.groupby(group_keys)[[pct_col, att_col]]\n",
    "                  .apply(\n",
    "                      lambda g: pd.Series({\n",
    "                          # Weighted average of top_choice / Moyenne pondérée du top_choice\n",
    "                          pct_col: (g[pct_col] * g[att_col]).sum() / g[att_col].sum()\n",
    "                                   if g[att_col].sum() > 0 else 0.0,\n",
    "\n",
    "                          # Average number of decisions per match / Nombre moyen de décisions par match\n",
    "                          att_col: g[att_col].mean()\n",
    "                      })\n",
    "                  )\n",
    "                  .reset_index()\n",
    "        )\n",
    "        frames_choice.append(tmp)\n",
    "\n",
    "    totals_choice = (\n",
    "        reduce(lambda left, right: left.merge(right, on=group_keys, how=\"outer\"), frames_choice)\n",
    "        if frames_choice else None\n",
    "    )\n",
    "\n",
    "    # Merge all metrics / Fusion finale des métriques\n",
    "    if totals_choice is not None:\n",
    "        totals = agg_other.merge(totals_choice, on=group_keys, how=\"left\")\n",
    "    else:\n",
    "        totals = agg_other.copy()\n",
    "\n",
    "    # Add minutes and matches / Ajout minutes et matchs\n",
    "    players_table = (\n",
    "        totals.merge(minutes_total, on=group_keys, how=\"left\")\n",
    "              .merge(match_played,  on=group_keys, how=\"left\")\n",
    "    )\n",
    "\n",
    "    players_table[\"match_played\"] = players_table[\"match_played\"].fillna(0).astype(int)\n",
    "\n",
    "    # Remove players under 90 minutes played / Enlever les joueurs ayant moins de 90 minutes jouées\n",
    "    players_table = players_table[players_table[\"minutes_total\"] >= 90]\n",
    "\n",
    "    # per90 only for non-top_choice metrics / per90 seulement pour les métriques non top_choice\n",
    "    if per90:\n",
    "        for c in other_cols:\n",
    "            per90_col = f\"{c}_per90\"\n",
    "            players_table[per90_col] = np.where(\n",
    "                players_table[\"minutes_total\"] > 0,\n",
    "                90 * players_table[c] / players_table[\"minutes_total\"],\n",
    "                0.0\n",
    "            )\n",
    "\n",
    "    # Rounding / Arrondis\n",
    "    for c in players_table.columns:\n",
    "        if c not in group_keys:\n",
    "            players_table[c] = pd.to_numeric(players_table[c], errors=\"coerce\").fillna(0.0).round(2)\n",
    "\n",
    "    # Save / Sauvegarde\n",
    "    out_path = os.path.join(out_dir, out_name)\n",
    "    players_table.to_csv(out_path, index=False)\n",
    "    print(\"Player table written / Table joueurs écrite\")\n",
    "\n",
    "    return players_table\n",
    "\n",
    "# Function execution / Exécution de la fonction\n",
    "players_df = build_players_table(result_df, player_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7f2d5-81b8-41d1-8162-30061125760e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
